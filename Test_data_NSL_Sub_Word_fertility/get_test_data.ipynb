{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "088ee9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "\n",
    "def extract_sentences_as_list(gz_file, lang_name, num_sentences=50, output_file=\"output.json\"):\n",
    "    sentences = []\n",
    "\n",
    "    with gzip.open(gz_file, 'rt', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= num_sentences:\n",
    "                break\n",
    "            sentence = line.strip()\n",
    "            if sentence:\n",
    "                sentences.append(sentence)\n",
    "\n",
    "    data = {\n",
    "        lang_name: sentences  # list of strings\n",
    "    }\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as out_f:\n",
    "        json.dump(data, out_f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Example usage\n",
    "extract_sentences_as_list(r\"C:\\Users\\Aish\\Downloads\\yo (1).txt.gz\", \"Yoruba\", num_sentences=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbbca10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import csv\n",
    "import json\n",
    "\n",
    "def extract_long_bengali_sentences_from_bz2(input_file, output_file=\"bengali_sentences.json\", num_sentences=50):\n",
    "    all_sentences = []\n",
    "\n",
    "    with bz2.open(input_file, 'rt', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            if len(row) < 3:\n",
    "                continue\n",
    "            # Join tokens from column 3 onwards (skip ID and 'ben')\n",
    "            sentence = \" \".join(row[2:]).strip()\n",
    "            if sentence:\n",
    "                all_sentences.append(sentence)\n",
    "\n",
    "    # Sort by length (number of words), descending\n",
    "    all_sentences.sort(key=lambda s: len(s.split()), reverse=True)\n",
    "\n",
    "    # Take top N\n",
    "    selected_sentences = all_sentences[:num_sentences]\n",
    "\n",
    "    data = {\"Bengali\": selected_sentences}\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as out_f:\n",
    "        json.dump(data, out_f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Example usage:\n",
    "extract_long_bengali_sentences_from_bz2(r\"C:\\Users\\Aish\\Downloads\\ben_sentences.tsv.bz2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10e4399c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing Arabic...\n",
      "📂 Processing Mandarin_Chinese...\n",
      "📂 Processing Russian...\n",
      "📂 Processing Hindi...\n",
      "📂 Processing Japanese...\n",
      "📂 Processing Swahili...\n",
      "📂 Processing Yoruba...\n",
      "📂 Processing Turkish...\n",
      "📂 Processing Bengali...\n",
      "\n",
      "✅ Final JSON written to final_multilang_sentences.json\n"
     ]
    }
   ],
   "source": [
    "import bz2\n",
    "import gzip\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "\n",
    "def extract_sentences_from_gz(file_path, lang_name, num_sentences=50):\n",
    "    sentences = []\n",
    "    with gzip.open(file_path, 'rt', encoding='utf-8', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            sentence = line.strip()\n",
    "            if sentence and len(sentence)>=20:\n",
    "                sentences.append(sentence)\n",
    "            if len(sentences) >= num_sentences:\n",
    "                break\n",
    "    return sentences\n",
    "\n",
    "def extract_sentences_from_bz2_tsv(file_path, lang_name, num_sentences=50):\n",
    "    all_sentences = []\n",
    "    with bz2.open(file_path, 'rt', encoding='utf-8', errors='ignore') as f:\n",
    "        reader = csv.reader((line.replace('\\x00', '') for line in f), delimiter='\\t')\n",
    "        for row in reader:\n",
    "            if len(row) < 3:\n",
    "                continue\n",
    "            sentence = \" \".join(row[2:]).strip()\n",
    "            if sentence:\n",
    "                all_sentences.append(sentence)\n",
    "    all_sentences.sort(key=lambda s: len(s.split()), reverse=True)\n",
    "    return all_sentences[:num_sentences]\n",
    "\n",
    "def process_all_languages(file_info, output_file=\"final_multilang_sentences.json\", num_sentences=50):\n",
    "    final_data = {}\n",
    "\n",
    "    for lang_name, file_path in file_info:\n",
    "        print(f\"📂 Processing {lang_name}...\")\n",
    "        try:\n",
    "            if file_path.endswith('.gz'):\n",
    "                sentences = extract_sentences_from_gz(file_path, lang_name, num_sentences)\n",
    "            elif file_path.endswith('.bz2'):\n",
    "                sentences = extract_sentences_from_bz2_tsv(file_path, lang_name, num_sentences)\n",
    "            else:\n",
    "                print(f\"⚠️ Unsupported format for {lang_name}: {file_path}\")\n",
    "                continue\n",
    "\n",
    "            final_data[lang_name] = sentences\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {lang_name}: {e}\")\n",
    "            final_data[lang_name] = []\n",
    "\n",
    "    # Write to final JSON\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(final_data, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"\\n✅ Final JSON written to {output_file}\")\n",
    "\n",
    "# Example input mapping\n",
    "file_info = [\n",
    "    (\"Arabic\", r\"C:\\Users\\Aish\\Downloads\\ar.txt.gz\"),\n",
    "    (\"Mandarin_Chinese\", r\"C:\\Users\\Aish\\Downloads\\zh.txt.gz\"),\n",
    "    (\"Russian\", r\"C:\\Users\\Aish\\Downloads\\ru.txt.gz\"),\n",
    "    (\"Hindi\", r\"C:\\Users\\Aish\\Downloads\\hi.txt.gz\"),\n",
    "    (\"Japanese\", r\"C:\\Users\\Aish\\Downloads\\ja.txt.gz\"),\n",
    "    (\"Swahili\", r\"C:\\Users\\Aish\\Downloads\\sw.txt.gz\"),\n",
    "    (\"Yoruba\", r\"C:\\Users\\Aish\\Downloads\\yor_sentences.tsv.bz2\"),\n",
    "    (\"Turkish\", r\"C:\\Users\\Aish\\Downloads\\tr.txt.gz\"),\n",
    "    (\"Bengali\", r\"C:\\Users\\Aish\\Downloads\\ben_sentences.tsv.bz2\")\n",
    "]\n",
    "\n",
    "# Run the processor\n",
    "process_all_languages(file_info, output_file=\"final_multilang_sentences.json\", num_sentences=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97e4570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
